{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV1-Coklat Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d35PFgmaAp4H",
        "colab_type": "code",
        "outputId": "86111de5-5215-4b4a-92a8-5f1505872761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb2XqlVNBygm",
        "colab_type": "code",
        "outputId": "aef23f72-4a60-4feb-dde0-c79fc48ab374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/'My Drive'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qp1gpYiCDGV",
        "colab_type": "code",
        "outputId": "9100999d-5084-4b31-aec8-dccec923364d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHmTSFXsI6El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YenaZlGJCQt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((224, 224))\n",
        "image_size = 0\n",
        "directory_root = './Dataset Coklat/'\n",
        "width=224\n",
        "height=224\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLgYlAZWCd2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX2QdGvgCpzs",
        "colab_type": "code",
        "outputId": "90cb0219-f341-40eb-df48-4faf42ec84bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    %time print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Moldy_Cocoa ...\n",
            "[INFO] Processing Broken_Beans_Cocoa ...\n",
            "[INFO] Processing Fermented_Cocoa ...\n",
            "[INFO] Processing Unfermented_Cocoa ...\n",
            "[INFO] Processing Bean_Fraction_Cocoa ...\n",
            "[INFO] Processing Whole_Beans_Cocoa ...\n",
            "[INFO] Image loading completed\n",
            "CPU times: user 467 µs, sys: 0 ns, total: 467 µs\n",
            "Wall time: 474 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOYVJmcoD--2",
        "colab_type": "code",
        "outputId": "31ec8461-fc3c-4567-9f97-3a1d137d52a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "image_size = len(image_list)\n",
        "image_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSYkkMqnEE3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4vq2yBFEI9k",
        "colab_type": "code",
        "outputId": "5175f14a-77cf-49f0-88a2-7a1bc14017a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bean_Fraction_Cocoa' 'Broken_Beans_Cocoa' 'Fermented_Cocoa'\n",
            " 'Moldy_Cocoa' 'Unfermented_Cocoa' 'Whole_Beans_Cocoa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5axAW8Z6EQYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN7wj5tAESnm",
        "colab_type": "code",
        "outputId": "e28c6a8e-b5ec-418d-98f6-35aa8f1f6c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59AbiLZsEY8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAurzuavEee6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Inception Model\n",
        "\n",
        "# Impor paket yang diperlukan Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# Inisialisasi Core\n",
        "kernel_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "# Inisialisasi offset\n",
        "bias_init = tf.keras.initializers.Constant(value=0.2)\n",
        "\n",
        "\n",
        "# Fungsi yang menghasilkan Modul Inception\n",
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "\n",
        "    # Konvolusi 1 × 1\n",
        "    conv_1x1 = Conv2D(filters_1x1,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_1x1 = BatchNormalization()(conv_1x1)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk reduksi dimensi Konvolusi 3x3\n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
        "\n",
        "    # Konvolusi 3x3\n",
        "    conv_3x3 = Conv2D(filters_3x3,\n",
        "                      (3, 3),\n",
        "                      padding='same',\n",
        "                      activation='relu')(conv_3x3)\n",
        "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk reduksi dimensi Konvolusi 5x5\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
        "\n",
        "    # Konvolusi 5x5\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5),\n",
        "                      padding='same',\n",
        "                      activation='relu')(conv_5x5)\n",
        "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
        "\n",
        "    # Max pooling\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk mencerna dimensi maksimum yang dikurangi\n",
        "    pool_proj = Conv2D(filters_pool_proj,\n",
        "                       (1, 1),\n",
        "                       padding='same',\n",
        "                       activation='relu')(pool_proj)\n",
        "    pool_proj = BatchNormalization()(pool_proj)\n",
        "\n",
        "    # Stack merge\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0pTOCZiE2re",
        "colab_type": "code",
        "outputId": "38ef83f3-d7a0-47eb-c005-589c76515e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Impor paket yang diperlukan\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Mendefinisikan GoogleNet / Inception-V1\n",
        "class GoogleNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, channel, classes):\n",
        "\n",
        "        input_layer = Input(shape=(width, height, channel))\n",
        "\n",
        "        # Inisialisasi inti\n",
        "        kernel_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "        # Inisialisasi offset\n",
        "        bias_init = tf.keras.initializers.Constant(value=0.2)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(64,\n",
        "                   (7, 7),\n",
        "                   padding='same',\n",
        "                   strides=(2, 2),\n",
        "                   activation='relu',\n",
        "                   name='conv_1_7x7/2')(input_layer)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(64,\n",
        "                   (1, 1),\n",
        "                   padding='same',\n",
        "                   strides=(1, 1),\n",
        "                   activation='relu',\n",
        "                   name='conv_2a_3x3/1')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(192,\n",
        "                   (3, 3),\n",
        "                   padding='same',\n",
        "                   strides=(1, 1),\n",
        "                   activation='relu',\n",
        "                   name='conv_2b_3x3/1')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=64,\n",
        "                             filters_3x3_reduce=96,\n",
        "                             filters_3x3=128,\n",
        "                             filters_5x5_reduce=16,\n",
        "                             filters_5x5=32,\n",
        "                             filters_pool_proj=32,\n",
        "                             name='inception_3a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=128,\n",
        "                             filters_3x3_reduce=128,\n",
        "                             filters_3x3=192,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=96,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_3b')\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=192,\n",
        "                             filters_3x3_reduce=96,\n",
        "                             filters_3x3=208,\n",
        "                             filters_5x5_reduce=16,\n",
        "                             filters_5x5=48,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=160,\n",
        "                             filters_3x3_reduce=112,\n",
        "                             filters_3x3=224,\n",
        "                             filters_5x5_reduce=24,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4b')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=128,\n",
        "                             filters_3x3_reduce=128,\n",
        "                             filters_3x3=256,\n",
        "                             filters_5x5_reduce=24,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4c')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=112,\n",
        "                             filters_3x3_reduce=144,\n",
        "                             filters_3x3=288,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4d')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=256,\n",
        "                             filters_3x3_reduce=160,\n",
        "                             filters_3x3=320,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_4e')\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=256,\n",
        "                             filters_3x3_reduce=160,\n",
        "                             filters_3x3=320,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_5a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=384,\n",
        "                             filters_3x3_reduce=192,\n",
        "                             filters_3x3=384,\n",
        "                             filters_5x5_reduce=48,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_5b')\n",
        "\n",
        "        # Global Avarage Pooling\n",
        "        x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "\n",
        "        # Random inactivation\n",
        "        x = Dropout(0.40)(x)\n",
        "\n",
        "        # Full connection/output\n",
        "        x = Dense(classes, activation='softmax', name='output')(x)\n",
        "\n",
        "        # Create GoogleNet model\n",
        "        # return Model(input_layer, [x, x1, x2], name='inception_v1')\n",
        "        return Model(input_layer, x, name='inception_v1')\n",
        "\n",
        "\n",
        "# Test GoogleNet class instantiation and output summary information of GoogleNet model\n",
        "if __name__ == \"__main__\":\n",
        "    model = GoogleNet.build(width=224, height=224, channel=3, classes=6)\n",
        "    print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1_7x7/2 (Conv2D)           (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv_1_7x7/2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_1_3x3/2 (MaxPooling2D) (None, 56, 56, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv_2a_3x3/1 (Conv2D)          (None, 56, 56, 64)   4160        max_pool_1_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv_2a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_2b_3x3/1 (Conv2D)          (None, 56, 56, 192)  110784      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 56, 56, 192)  768         conv_2b_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_2_3x3/2 (MaxPooling2D) (None, 28, 28, 192)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 96)   18528       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 16)   3088        max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 28, 96)   384         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 28, 28, 192)  0           max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 64)   12352       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 128)  110720      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 32)   12832       batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 32)   6176        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 28, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 28, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a (Concatenate)      (None, 28, 28, 256)  0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 32)   8224        inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 256)  0           inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 192)  221376      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 96)   76896       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 64)   16448       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 28, 192)  768         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 96)   384         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b (Concatenate)      (None, 28, 28, 480)  0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_3_3x3/2 (MaxPooling2D) (None, 14, 14, 480)  0           inception_3b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 14, 14, 96)   46176       max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 16)   7696        max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 14, 14, 96)   384         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 14, 14, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 480)  0           max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 192)  92352       max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 208)  179920      batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 48)   19248       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 64)   30784       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 192)  768         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 14, 14, 208)  832         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 14, 14, 48)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 14, 14, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_15[0][0]     \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 112)  57456       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 14, 14, 24)   12312       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 14, 14, 112)  448         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 14, 14, 24)   96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 160)  82080       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 224)  226016      batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 14, 14, 64)   38464       batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 14, 14, 160)  640         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 14, 14, 224)  896         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 14, 14, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4b (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_21[0][0]     \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 14, 14, 24)   12312       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 14, 14, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 24)   96          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 256)  295168      batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 14, 14, 64)   38464       batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 14, 14, 128)  512         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 64)   256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 64)   256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4c (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_27[0][0]     \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 144)  73872       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 32)   16416       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 144)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 112)  57456       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 288)  373536      batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 64)   51264       batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 112)  448         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 288)  1152        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 64)   256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 64)   256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4d (Concatenate)      (None, 14, 14, 528)  0           batch_normalization_33[0][0]     \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 160)  84640       inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 32)   16928       inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 160)  640         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 32)   128         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 528)  0           inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 256)  135424      inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 320)  461120      batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 128)  102528      batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 128)  67712       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 320)  1280        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 14, 14, 128)  512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 14, 14, 128)  512         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e (Concatenate)      (None, 14, 14, 832)  0           batch_normalization_39[0][0]     \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_4_3x3/2 (MaxPooling2D) (None, 7, 7, 832)    0           inception_4e[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 160)    133280      max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 32)     26656       max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    640         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 32)     128         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 832)    0           max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 256)    213248      max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 320)    461120      batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 128)    102528      batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 320)    1280        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 128)    512         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 128)    512         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a (Concatenate)      (None, 7, 7, 832)    0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    159936      inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 48)     39984       inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 192)    768         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 48)     192         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 832)    0           inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 384)    319872      inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 384)    663936      batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 128)    153728      batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 384)    1536        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 384)    1536        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 128)    512         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 128)    512         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b (Concatenate)      (None, 7, 7, 1024)   0           batch_normalization_51[0][0]     \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "                                                                 batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool_5_3x3/1 (GlobalAverage (None, 1024)         0           inception_5b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           avg_pool_5_3x3/1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 6)            6150        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,008,822\n",
            "Trainable params: 5,994,262\n",
            "Non-trainable params: 14,560\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq18ZeGsE-jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZb2Brk1FDQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer='Adam',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw16VD1dFHxg",
        "colab_type": "code",
        "outputId": "484be5e0-ebb0-4b61-b7a2-d152004426a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    validation_steps=1200// BS,\n",
        "    max_queue_size=BS*2,\n",
        "    verbose=1\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "14/15 [===========================>..] - ETA: 10s - loss: 0.5357 - acc: 0.8357Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 10s 81ms/sample - loss: 0.5275 - acc: 0.8333\n",
            "15/15 [==============================] - 164s 11s/step - loss: 0.5295 - acc: 0.8355 - val_loss: 0.5207 - val_acc: 0.8333\n",
            "Epoch 2/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.3670 - acc: 0.8536 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.6452 - acc: 0.7154\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.3729 - acc: 0.8519 - val_loss: 1.6165 - val_acc: 0.7154\n",
            "Epoch 3/50\n",
            "14/15 [===========================>..] - ETA: 10s - loss: 0.2622 - acc: 0.8921Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 2.1167 - acc: 0.7154\n",
            "15/15 [==============================] - 159s 11s/step - loss: 0.2684 - acc: 0.8882 - val_loss: 2.0936 - val_acc: 0.7154\n",
            "Epoch 4/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.2358 - acc: 0.9064 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.2686 - acc: 0.7615\n",
            "15/15 [==============================] - 145s 10s/step - loss: 0.2425 - acc: 0.9033 - val_loss: 1.1941 - val_acc: 0.7615\n",
            "Epoch 5/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1870 - acc: 0.9141 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.3610 - acc: 0.7209\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.1872 - acc: 0.9143 - val_loss: 1.2520 - val_acc: 0.7209\n",
            "Epoch 6/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.2186 - acc: 0.9141 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.9010 - acc: 0.7154\n",
            "15/15 [==============================] - 151s 10s/step - loss: 0.2139 - acc: 0.9150 - val_loss: 1.8322 - val_acc: 0.7154\n",
            "Epoch 7/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.2081 - acc: 0.9077 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 2.6612 - acc: 0.7154\n",
            "15/15 [==============================] - 158s 11s/step - loss: 0.2043 - acc: 0.9094 - val_loss: 2.6374 - val_acc: 0.7154\n",
            "Epoch 8/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.2008 - acc: 0.9179 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 3.3341 - acc: 0.7154\n",
            "15/15 [==============================] - 145s 10s/step - loss: 0.2003 - acc: 0.9167 - val_loss: 3.3062 - val_acc: 0.7154\n",
            "Epoch 9/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.2071 - acc: 0.9148 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.9502 - acc: 0.7154\n",
            "15/15 [==============================] - 158s 11s/step - loss: 0.2139 - acc: 0.9135 - val_loss: 1.8797 - val_acc: 0.7154\n",
            "Epoch 10/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1942 - acc: 0.9102 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 74ms/sample - loss: 3.2296 - acc: 0.7154\n",
            "15/15 [==============================] - 145s 10s/step - loss: 0.2044 - acc: 0.9091 - val_loss: 2.9262 - val_acc: 0.7154\n",
            "Epoch 11/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1852 - acc: 0.9230 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 3.3489 - acc: 0.7154\n",
            "15/15 [==============================] - 158s 11s/step - loss: 0.1864 - acc: 0.9222 - val_loss: 3.3221 - val_acc: 0.7154\n",
            "Epoch 12/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1948 - acc: 0.9251 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 2.5426 - acc: 0.7154\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.1943 - acc: 0.9248 - val_loss: 2.4426 - val_acc: 0.7154\n",
            "Epoch 13/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1738 - acc: 0.9333 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.9664 - acc: 0.7154\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.1808 - acc: 0.9281 - val_loss: 1.8557 - val_acc: 0.7154\n",
            "Epoch 14/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1550 - acc: 0.9352 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 2.6293 - acc: 0.7209\n",
            "15/15 [==============================] - 151s 10s/step - loss: 0.1504 - acc: 0.9379 - val_loss: 2.4442 - val_acc: 0.7209\n",
            "Epoch 15/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1638 - acc: 0.9325 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.6516 - acc: 0.7344\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.1640 - acc: 0.9310 - val_loss: 1.5927 - val_acc: 0.7344\n",
            "Epoch 16/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1474 - acc: 0.9344 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.6125 - acc: 0.7154\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.1511 - acc: 0.9325 - val_loss: 1.6006 - val_acc: 0.7154\n",
            "Epoch 17/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1553 - acc: 0.9352 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 0.6149 - acc: 0.7873\n",
            "15/15 [==============================] - 148s 10s/step - loss: 0.1521 - acc: 0.9361 - val_loss: 0.5840 - val_acc: 0.7873\n",
            "Epoch 18/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1251 - acc: 0.9551 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.4271 - acc: 0.8442\n",
            "15/15 [==============================] - 153s 10s/step - loss: 0.1287 - acc: 0.9539 - val_loss: 0.4184 - val_acc: 0.8442\n",
            "Epoch 19/50\n",
            "14/15 [===========================>..] - ETA: 10s - loss: 0.1349 - acc: 0.9468Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.4663 - acc: 0.8550\n",
            "15/15 [==============================] - 160s 11s/step - loss: 0.1349 - acc: 0.9472 - val_loss: 0.4619 - val_acc: 0.8550\n",
            "Epoch 20/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1576 - acc: 0.9407 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 74ms/sample - loss: 0.4397 - acc: 0.8171\n",
            "15/15 [==============================] - 148s 10s/step - loss: 0.1556 - acc: 0.9399 - val_loss: 0.5663 - val_acc: 0.8171\n",
            "Epoch 21/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1713 - acc: 0.9305 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.7202 - acc: 0.7859\n",
            "15/15 [==============================] - 154s 10s/step - loss: 0.1669 - acc: 0.9317 - val_loss: 0.6379 - val_acc: 0.7859\n",
            "Epoch 22/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1324 - acc: 0.9493 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 0.4530 - acc: 0.8428\n",
            "15/15 [==============================] - 153s 10s/step - loss: 0.1283 - acc: 0.9506 - val_loss: 0.4188 - val_acc: 0.8428\n",
            "Epoch 23/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1167 - acc: 0.9546 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.6641 - acc: 0.7846\n",
            "15/15 [==============================] - 159s 11s/step - loss: 0.1204 - acc: 0.9535 - val_loss: 0.6512 - val_acc: 0.7846\n",
            "Epoch 24/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1620 - acc: 0.9321 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 0.7642 - acc: 0.7913\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.1638 - acc: 0.9310 - val_loss: 0.6507 - val_acc: 0.7913\n",
            "Epoch 25/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1992 - acc: 0.9243 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.8403 - acc: 0.7859\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.1944 - acc: 0.9274 - val_loss: 0.7323 - val_acc: 0.7859\n",
            "Epoch 26/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1577 - acc: 0.9418 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.2379 - acc: 0.7480\n",
            "15/15 [==============================] - 153s 10s/step - loss: 0.1614 - acc: 0.9397 - val_loss: 1.1322 - val_acc: 0.7480\n",
            "Epoch 27/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1354 - acc: 0.9551 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.6493 - acc: 0.8022\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.1331 - acc: 0.9561 - val_loss: 0.5567 - val_acc: 0.8022\n",
            "Epoch 28/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1336 - acc: 0.9426 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.5174 - acc: 0.8293\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.1400 - acc: 0.9408 - val_loss: 0.4530 - val_acc: 0.8293\n",
            "Epoch 29/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1259 - acc: 0.9504 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.1101 - acc: 0.7710\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.1235 - acc: 0.9503 - val_loss: 0.9973 - val_acc: 0.7710\n",
            "Epoch 30/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1209 - acc: 0.9477 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.1637 - acc: 0.7778\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.1256 - acc: 0.9459 - val_loss: 0.9738 - val_acc: 0.7778\n",
            "Epoch 31/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1245 - acc: 0.9442 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.3425 - acc: 0.7710\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.1331 - acc: 0.9415 - val_loss: 1.1568 - val_acc: 0.7710\n",
            "Epoch 32/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1564 - acc: 0.9415 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 76ms/sample - loss: 1.6658 - acc: 0.7575\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.1528 - acc: 0.9412 - val_loss: 1.6048 - val_acc: 0.7575\n",
            "Epoch 33/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.0990 - acc: 0.9590 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.3638 - acc: 0.7900\n",
            "15/15 [==============================] - 152s 10s/step - loss: 0.1005 - acc: 0.9586 - val_loss: 1.3012 - val_acc: 0.7900\n",
            "Epoch 34/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1365 - acc: 0.9496 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 2.3291 - acc: 0.7412\n",
            "15/15 [==============================] - 157s 10s/step - loss: 0.1349 - acc: 0.9506 - val_loss: 2.3124 - val_acc: 0.7412\n",
            "Epoch 35/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1415 - acc: 0.9407 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 0.3827 - acc: 0.8821\n",
            "15/15 [==============================] - 154s 10s/step - loss: 0.1353 - acc: 0.9437 - val_loss: 0.3575 - val_acc: 0.8821\n",
            "Epoch 36/50\n",
            "14/15 [===========================>..] - ETA: 10s - loss: 0.1226 - acc: 0.9468Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.0838 - acc: 0.8076\n",
            "15/15 [==============================] - 161s 11s/step - loss: 0.1283 - acc: 0.9455 - val_loss: 0.9288 - val_acc: 0.8076\n",
            "Epoch 37/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1618 - acc: 0.9388 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 74ms/sample - loss: 0.6138 - acc: 0.8211\n",
            "15/15 [==============================] - 151s 10s/step - loss: 0.1604 - acc: 0.9380 - val_loss: 0.5452 - val_acc: 0.8211\n",
            "Epoch 38/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1380 - acc: 0.9493 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.2874 - acc: 0.8117\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.1388 - acc: 0.9488 - val_loss: 1.1753 - val_acc: 0.8117\n",
            "Epoch 39/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1083 - acc: 0.9571 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.9478 - acc: 0.7873\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.1075 - acc: 0.9561 - val_loss: 0.9273 - val_acc: 0.7873\n",
            "Epoch 40/50\n",
            "14/15 [===========================>..] - ETA: 10s - loss: 0.1139 - acc: 0.9594Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.9691 - acc: 0.7561\n",
            "15/15 [==============================] - 160s 11s/step - loss: 0.1118 - acc: 0.9601 - val_loss: 1.8934 - val_acc: 0.7561\n",
            "Epoch 41/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1129 - acc: 0.9532 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.2917 - acc: 0.7696\n",
            "15/15 [==============================] - 146s 10s/step - loss: 0.1116 - acc: 0.9543 - val_loss: 1.3345 - val_acc: 0.7696\n",
            "Epoch 42/50\n",
            "14/15 [===========================>..] - ETA: 10s - loss: 0.1174 - acc: 0.9505Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 1.3052 - acc: 0.8157\n",
            "15/15 [==============================] - 159s 11s/step - loss: 0.1170 - acc: 0.9503 - val_loss: 1.4438 - val_acc: 0.8157\n",
            "Epoch 43/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1381 - acc: 0.9462 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 72ms/sample - loss: 0.8587 - acc: 0.8469\n",
            "15/15 [==============================] - 147s 10s/step - loss: 0.1347 - acc: 0.9479 - val_loss: 0.8024 - val_acc: 0.8469\n",
            "Epoch 44/50\n",
            "14/15 [===========================>..] - ETA: 10s - loss: 0.1011 - acc: 0.9591Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.8992 - acc: 0.7859\n",
            "15/15 [==============================] - 160s 11s/step - loss: 0.1026 - acc: 0.9576 - val_loss: 1.5988 - val_acc: 0.7859\n",
            "Epoch 45/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1156 - acc: 0.9543 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.6128 - acc: 0.8482\n",
            "15/15 [==============================] - 155s 10s/step - loss: 0.1116 - acc: 0.9561 - val_loss: 0.5120 - val_acc: 0.8482\n",
            "Epoch 46/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.0931 - acc: 0.9594 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.9440 - acc: 0.8455\n",
            "15/15 [==============================] - 156s 10s/step - loss: 0.0905 - acc: 0.9611 - val_loss: 0.7842 - val_acc: 0.8455\n",
            "Epoch 47/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.0995 - acc: 0.9660 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 2.2172 - acc: 0.7615\n",
            "15/15 [==============================] - 157s 10s/step - loss: 0.0968 - acc: 0.9662 - val_loss: 2.0240 - val_acc: 0.7615\n",
            "Epoch 48/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.0915 - acc: 0.9653 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 1.1068 - acc: 0.7846\n",
            "15/15 [==============================] - 157s 10s/step - loss: 0.0910 - acc: 0.9655 - val_loss: 0.9247 - val_acc: 0.7846\n",
            "Epoch 49/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1047 - acc: 0.9633 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 73ms/sample - loss: 0.3384 - acc: 0.9092\n",
            "15/15 [==============================] - 153s 10s/step - loss: 0.1012 - acc: 0.9648 - val_loss: 0.2905 - val_acc: 0.9092\n",
            "Epoch 50/50\n",
            "14/15 [===========================>..] - ETA: 9s - loss: 0.1059 - acc: 0.9594 Epoch 1/50\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 9s 74ms/sample - loss: 0.6720 - acc: 0.8591\n",
            "15/15 [==============================] - 157s 10s/step - loss: 0.1050 - acc: 0.9586 - val_loss: 0.6193 - val_acc: 0.8591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZH-ODSxlbet",
        "colab_type": "code",
        "outputId": "59fcc6b0-51e8-496c-e6dc-f15243de15ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB4gTugB4oQeIE7oAeKEHiBO6AHiHgP1KOWnHkMHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRNAFQRBswv8D7LDtvcgEbh4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jHogJSmlh8k",
        "colab_type": "code",
        "outputId": "616c3ee7-3463-47c7-b4c4-c4c2514b8d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Calculating model accuracy\n",
            "123/123 [==============================] - 9s 74ms/sample - loss: 0.6150 - acc: 0.8591\n",
            "Test Accuracy: 85.90786457061768\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}